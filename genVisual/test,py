from langchain.document_loaders import BSHTMLLoader, DirectoryLoader,TextLoader
import os
from langchain.text_splitter import RecursiveCharacterTextSplitter
from dotenv import find_dotenv, load_dotenv
dotenv_path= find_dotenv()
load_dotenv(dotenv_path)

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
SERPAPI_API_KEY = os.getenv("SERPAPI_API_KEY")
COHERE_API_KEY = os.getenv("COHERE_API_KEY")
os.environ["OPENAI_API_KEY"] ="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"
os.environ["SERPAPI_API_KEY"] ="84c5633c21ec443a55d46de3d8dcfe90218c061e0fae4ea4eb1573ae3f0b12fa"

txt_dir_loader = DirectoryLoader('C:\\Users\\DELL\\Desktop\\Marvin\\Gen_visual\\documentProcessing\\data', loader_cls=TextLoader)

txt_data = txt_dir_loader.load()


text_splitter = RecursiveCharacterTextSplitter(
    chunk_size = 1000,
    chunk_overlap  = 20,
    length_function = len,
)
txt_documents = text_splitter.split_documents(txt_data)

from langchain.embeddings.openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()

from langchain.vectorstores import Chroma

persist_directory = "vector_db"

vectordb = Chroma.from_documents(documents=txt_documents, embedding=embeddings, persist_directory=persist_directory)
vectordb.persist()
vectordb = None


vectordb = Chroma(persist_directory=persist_directory, embedding_function=embeddings)
vectordb.similarity_search("rabbit")

from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(temperature=0, model="gpt-3.5-turbo")

doc_retriever = vectordb.as_retriever()
from langchain.chains import RetrievalQA

# print(alice_qa.run("What is up with the Cheshire Cat?"))

from langchain.utilities import SerpAPIWrapper
from langchain.agents import initialize_agent, Tool
from langchain.agents import AgentType
from langchain.tools import BaseTool
from langchain.llms import OpenAI
from langchain import SerpAPIWrapper

search = SerpAPIWrapper()
# tools = [
#     Tool(
#         name = "Alice in Wonderland QA System",
#         func=alice_qa.run,
#         description="useful for when you need to answer questions about Alice in Wonderland. Input should be a fully formed question."
#     ),
#     Tool(
#         name = "Backup Alice Google Search",
#         func=search.run,
#         description="useful for when you need to answer questions about Alice in Wonderland but only when the Alice in Wonderland QA System couldn't answer the query. Input should be a fully formed question."
#     ),
# ]

# # agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)
# agent.run("What is the deal with the Cheshire Cat?")


from langchain.memory import ConversationBufferMemory, ReadOnlySharedMemory

memory = ConversationBufferMemory(memory_key="chat_history")
readonlymemory = ReadOnlySharedMemory(memory=memory)

alice_qa = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=doc_retriever, memory=readonlymemory)

tools = [
    Tool(
        name = "Alice in Wonderland QA System",
        func=alice_qa.run,
        description="useful for when you need to answer questions about Alice in Wonderland. Input should be a fully formed question."
    ),
    Tool(
        
        name = "Backup Alice Google Search",
        func=search.run,
        description="useful for when you need to answer questions about Alice in Wonderland but only when the Alice in Wonderland QA System couldn't answer the query. Input should be a fully formed question."
    ),
]

from langchain.agents import ZeroShotAgent, Tool, AgentExecutor

prefix = """Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:"""
suffix = """Begin!"

{chat_history}
Question: {input}
{agent_scratchpad}"""

prompt = ZeroShotAgent.create_prompt(
    tools,
    prefix=prefix,
    suffix=suffix,
    input_variables=["input", "chat_history", "agent_scratchpad"]
)

from langchain import OpenAI, LLMChain, PromptTemplate
llm_chain = LLMChain(llm=llm, prompt=prompt)

agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)
agent_chain = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True, memory=memory)
print(agent_chain.run(input="What is the deal with the Cheshire Cat?"))